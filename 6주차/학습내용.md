6주차 (2020.11.7 ~ 2020.11.13)

# 형태소 분석
    저번주차에 JSON파일에서 대화부분을 받아오는 실습을 하였다. 
    이 코드를 이용하여 사용자의 감정을 분석하기 위해서는 사용자의 대화에서 감정을 나타내는 
    '걱정', '불안', '기쁨' 등의 단어를 찾아내야 한다고 생각해 대화를 형태소 분석해야한다고 생각했다.
    그래서 가져온 list를 각각 형태소 분석하는 실습을 했다. Komoran을 통해 형태소 분석을 해보았다.

![komoran1](https://user-images.githubusercontent.com/72618459/99279349-7c7f4e00-2873-11eb-84b7-c0623e17eebb.PNG)

# OKT 형태소 분석
    다른 형태소 분석 방법에 대해 알아 보았는데 OKT와 꼬꼬마 라는 형태소 분석 방법이 더 있었다. 
    더 필요한 분석을 위해 모두 실행해 보았다. 같은 형태로 데이터 3가지를 list로 받아와 okt 분석을 해보았다.
![okt 1](https://user-images.githubusercontent.com/72618459/99280586-d92f3880-2874-11eb-9eaf-c82d6660f51f.PNG)

# 꼬꼬마 형태소 분석
    꼬꼬마 형태소 분석에는 3가지 방법이 있었는데, 3가지를 모두 해보았다. 
    실행 결과를 보아 kkma.nouns 부분보다는 kkma.morphs 이나 kkma.pos 를 사용하는 것이 좋아보였다.
![꼬꼬마 1](https://user-images.githubusercontent.com/72618459/99280589-da606580-2874-11eb-8f1b-f9ca0eb08eab.PNG)

# 머신러닝 플로우
형태소 분석을 마친 후 머신 러닝에 대해 
	흐름을 알아야겠다고 생각했다.
	머신러닝은 6단계로 나눌 수 있다.
		
	1) 수집
		기계에 학습시켜야 할 데이터가 필요.
		자연어 데이터를 말뭉치 또는 코퍼스(corpus) 라고 부른다.

	2) 점검 및 탐색
		데이터를 점검하고 탐색.
		데이터의 구조, 노이즈 데이터, 머신 러닝 적용을 위해 
		데이터를 어떻게 정제해야하는지 파악.
		탐색적 데이터 분석(Exploratory Data Analysis, EDA) 
		단계라고 한다.
			데이터의 특징과 내재하는 구조적 관계를 알아내는 과정
			시각화와 간단한 통계 테스트 진행하기도 함.

	3) 전처리 및 정제
		자연어 처리라면 토큰화, 정제, 정규화, 불용어 제거 등의 
		단계를 포함한다.

	4) 모델링 및 훈련
		머신 러닝에 대한 코드를 작성하는 단계
		적절한 머신 러닝 알고리즘을 선택하여 모델링이 끝났다면 
		전처리가 완료 된 데이터를 머신 러닝 알고리즘을 통해 
		기계에계 학습시킨다. 이를 훈련이라고도 한다.
		모든 데이터를 기계에게 학습시켜서는 안 된다.
		데이터 중 일부는 테스트용으로 남겨두고 훈련용 데이터만 
		훈련에 사용한다.
		그래야만 현재 성능이 얼마나 되는지를 측정할 수 있으며, 
		과적합(overfitting) 상황을 막을 수 있다. 
		데이터의 양이 충분하면 훈련용, 검증용, 테스트용 
		이렇게 세가지로 나눌 수 있다.
		검증용 데이터를 통해 모델의 성능을 개선한다. 
		테스트용 데이터는 모델의 성능을 수치화 하여 
		평가하기 위해 사용된다.

	5) 평가
		테스트용 데이터로 성능을 평가한다.

	6) 배포

# torchtext
이 학습 방법에 대해 자연어 처리를 알아보았는데
대부분의 경우에는 -1 부터 1의 값으로 나타내 긍정과 부정을 알아보는 예제들이 많았다.
그렇게 알게 된 부분이 torchtext이다.
pytorch tutorial에 나와 있는 예제를 알아봤다.
이 예제는 AG의 뉴스를 가져와 World, Sports, Business, Sci/Tec
의 4가지 분류로 나누어 학습한 후 문장을 보고 그 뉴스가 어떤 뉴스인지 알아낼 수 있게 해주는 예제이다.
이 예제가 감정분석에 활용할 수 있을정도의 정확도인지 확인해보기 위해 한글로 된 테크 뉴스를 가져와 영어로 변역기를 돌린 뒤 테스트 해보았다. 
![torchtext 실행결과](https://user-images.githubusercontent.com/72618459/99876330-7f928980-2c39-11eb-88ed-fb873c02d515.PNG)

한국어 뉴스를 단순 번역기에 넣어 예제 실습을 해 보았을 뿐인데 꽤 정확하다는 생각이 들어 이 예제를 해커톤에 적용해보기로 했다.

# 모델 정의
EmbeddingBag, 선형 레이어
	
	EmbeddingBag은 임베딩들로 구성된 가방의 평균을 계산. 
	이때 텍스트의 각 원소는 그 길이가 다를 수 있다. 
	텍스트의 길이는 오프셋에 저장되어 있으므로 
	여기서 nn.EmbeddingBag에 패딩을 사용할 필요는 없다. 
	임베딩의 평균을 즉시 계산하기 때문에, 
	텐서들의 시퀀스를 처리할 때 성능 및 메모리 효율성 측면
	에서의 장점도 갖고 있다.

# 임베딩 층

	임베딩 층의 입력으로 사용하기 위해 입력 시퀀스의 각 단어들은 
	모두 정수 인코딩이 되어있어야 한다.
	임베딩 층은 입력 정수에 대해 밀집 벡터(dense vector)로 
	맵핑하고 이 밀집 벡터는 인공 신경망의 학습 과정에서 
	가중치가 학습되는 것과 같은 방식으로 훈련된다.
	훈련 과정에서 단어는 모델이 풀고자하는 작업에 맞는 값으로 
	업데이트 된다.
	이 밀집 벡터를 임베딩 벡터라고 부른다.
	ex) 단어 great은 정수 인코딩 과정에서 1918의 정수로 
	인코딩이 되었고 그에 따라 단어 집합의 크기만큼의 
	행을 가지는 테이블에서 인덱스 1918번에 위치한 행을 
	단어 great의 임베딩 벡터로 사용한다. 
	이 임베딩 벡터는 모델의 입력이 되고 
	역전파 과정에서 단어 great의 임베딩 벡터값이 학습된다.

# 실습

	1. 임의의 문장으로 단어 집합을 만들고 각 단어에 정수를 부여한다.
![1C](https://user-images.githubusercontent.com/72618459/99876440-18c1a000-2c3a-11eb-8753-6d42723b24dd.PNG)
![1S](https://user-images.githubusercontent.com/72618459/99876442-19f2cd00-2c3a-11eb-93a8-7c184b2c7552.PNG)

	2. 단어 집합의 크기를 행으로 가지는 임베딩 테이블을 구현한다.
![2](https://user-images.githubusercontent.com/72618459/99876444-19f2cd00-2c3a-11eb-8f65-ec44790ed318.PNG)

	3. 임의의 문장에 대해서 룩업 테이블을 통해 임베딩 벡터들을 가져온다.
![3C](https://user-images.githubusercontent.com/72618459/99876445-1a8b6380-2c3a-11eb-9262-5a496f799e76.PNG)
![3S](https://user-images.githubusercontent.com/72618459/99876447-1a8b6380-2c3a-11eb-8757-b239a9a81cc0.PNG)

	4. torch.LongTensor(idxes) 가 어떻게 구성되어있는지 알아보기 위해 print를 했다.
![4C](https://user-images.githubusercontent.com/72618459/99876449-1b23fa00-2c3a-11eb-82d8-10ea961cde00.PNG)
![4S](https://user-images.githubusercontent.com/72618459/99876450-1bbc9080-2c3a-11eb-8d5f-6b64f5a5e45a.PNG)

	5. "많아" 와 비슷한 "많다" 라는 단어를 통해 어떻게 구현되는지 알아봤다. 
	"많다"는 단어 집합에 들어가 있지 않았기 때문에 <unk>으로 처리되었다.
![5C](https://user-images.githubusercontent.com/72618459/99876451-1bbc9080-2c3a-11eb-8266-75ad7bb7c37d.PNG)
![5S](https://user-images.githubusercontent.com/72618459/99876454-1c552700-2c3a-11eb-9e59-59f13fcc8160.PNG)
